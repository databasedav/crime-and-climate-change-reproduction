{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import random\n",
    "import urllib\n",
    "import _pickle as pickle  # using cPickle\n",
    "import os.path\n",
    "import datetime\n",
    "import ipywidgets\n",
    "import ipyparallel\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data Documentation\n",
    "\n",
    "**Reference the docs here:**\n",
    "* https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/readme.txt\n",
    "* https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/ghcn-daily-by_year-format.rtf\n",
    "* https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt\n",
    "\n",
    "The second is a .rtf (Rich Text Format file; think Word) and it's contexts are copied below if you cannot open it:\n",
    "\n",
    "The following information serves as a definition of each field in one line of data covering one station-day. Each field described below is separated by a comma ( , ) and follows the order\n",
    "presented in this document.\n",
    "\n",
    "* ID = 11 character station identification code\n",
    "* YEAR/MONTH/DAY = 8 character date in YYYYMMDD format (e.g. 19860529 = May 29, 1986)\n",
    "* ELEMENT = 4 character indicator of element type \n",
    "* DATA VALUE = 5 character data value for ELEMENT \n",
    "* M-FLAG = 1 character Measurement Flag \n",
    "* Q-FLAG = 1 character Quality Flag \n",
    "* S-FLAG = 1 character Source Flag \n",
    "* OBS-TIME = 4-character time of observation in hour-minute format (i.e. 0700 =7:00 am)\n",
    "\n",
    "See section III of the GHCN-Daily readme.txt file for an explanation of ELEMENT codes and their units as well as the M-FLAG, Q-FLAGS and S-FLAGS.\n",
    "\n",
    "The OBS-TIME field is populated with the observation times contained in NOAA/NCDC’s Multinetwork Metadata System (MMS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/stations_df.pkl', 'rb') as file:\n",
    "    stations_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = stations_df[stations_df['ID'].str.startswith('US') & (stations_df['HCN/CRN FLAG'] == 'HCN')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GSN FLAG</th>\n",
       "      <th>HCN/CRN FLAG</th>\n",
       "      <th>WMO ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00011084</td>\n",
       "      <td>31.0583</td>\n",
       "      <td>-87.0550</td>\n",
       "      <td>25.9</td>\n",
       "      <td>AL</td>\n",
       "      <td>BREWTON 3 SSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HCN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00012813</td>\n",
       "      <td>30.5467</td>\n",
       "      <td>-87.8808</td>\n",
       "      <td>7.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>FAIRHOPE 2 NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HCN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00013160</td>\n",
       "      <td>32.8347</td>\n",
       "      <td>-88.1342</td>\n",
       "      <td>38.1</td>\n",
       "      <td>AL</td>\n",
       "      <td>GAINESVILLE LOCK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HCN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00013511</td>\n",
       "      <td>32.7019</td>\n",
       "      <td>-87.5814</td>\n",
       "      <td>67.4</td>\n",
       "      <td>AL</td>\n",
       "      <td>GREENSBORO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HCN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00013816</td>\n",
       "      <td>31.8814</td>\n",
       "      <td>-86.2503</td>\n",
       "      <td>132.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>HIGHLAND HOME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HCN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  LATITUDE  LONGITUDE  ELEVATION STATE              NAME  \\\n",
       "0  USC00011084   31.0583   -87.0550       25.9    AL     BREWTON 3 SSE   \n",
       "1  USC00012813   30.5467   -87.8808        7.0    AL     FAIRHOPE 2 NE   \n",
       "2  USC00013160   32.8347   -88.1342       38.1    AL  GAINESVILLE LOCK   \n",
       "3  USC00013511   32.7019   -87.5814       67.4    AL        GREENSBORO   \n",
       "4  USC00013816   31.8814   -86.2503      132.0    AL     HIGHLAND HOME   \n",
       "\n",
       "  GSN FLAG HCN/CRN FLAG  WMO ID  \n",
       "0      NaN          HCN     NaN  \n",
       "1      NaN          HCN     NaN  \n",
       "2      NaN          HCN     NaN  \n",
       "3      NaN          HCN     NaN  \n",
       "4      NaN          HCN     NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_format(yearmonthday):\n",
    "    return pd.Timestamp(datetime.datetime.strptime(str(yearmonthday), '%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading weather data for: 2009\n"
     ]
    }
   ],
   "source": [
    "for year in range(1980, 2010):\n",
    "    print(f'downloading weather data for: {year}')\n",
    "    clear_output(wait=True)\n",
    "    if os.path.isfile(f'weather_data/{year}.csv.gz'):\n",
    "        continue\n",
    "    url = f'http://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/{year}.csv.gz'\n",
    "    urllib.request.urlretrieve(url, f'weather_data/{year}.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict from year to cleaned weather dataframe\n",
    "weather_df_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 42s, sys: 33.8 s, total: 14min 16s\n",
      "Wall time: 12min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: parallelize the below (maybe)\n",
    "# no need to repeat after pickling (only ever do once)\n",
    "# time required estimate: 20-30+ minutes\n",
    "years = range(1980, 2010)\n",
    "for year in years:\n",
    "    print(f'cleaning dataframe for: {year} ({year-1980+1}/{len(years)})')\n",
    "    clear_output(wait=True)\n",
    "    df = pd.read_csv(\n",
    "        f'weather_data/{year}.csv.gz',\n",
    "        header=None,\n",
    "        names=['ID', 'YEARMONTHDAY', 'ELEMENT', 'DATA VALUE', 'M-FLAG', 'Q-FLAG', 'S-FLAG', 'OBS-TIME']\n",
    "    )\n",
    "    df = df[df['ID'].isin(stations_df['ID']) & (df['ELEMENT'].isin(['TMAX', 'PRCP']))]\n",
    "    df = df.assign(date=np.vectorize(date_format)(df['YEARMONTHDAY']))\n",
    "    df.drop(columns=['YEARMONTHDAY', 'M-FLAG', 'Q-FLAG', 'S-FLAG', 'OBS-TIME'], inplace=True)\n",
    "    weather_df_dict[year] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/weather_df_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(weather_df_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/weather_df_dict.pkl', 'rb') as file:\n",
    "    weather_df_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dfs = list()\n",
    "for year in range(1980, 2010):\n",
    "    temp_df = weather_df_dict[year]\n",
    "    temp_dfs.append(temp_df[temp_df['ELEMENT'] == 'TMAX'].drop(columns=['ELEMENT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df with all stations' tempurature time series\n",
    "all_temp_df = pd.concat(temp_dfs)\n",
    "all_temp_df.reset_index(drop=True, inplace=True)\n",
    "all_temp_df = all_temp_df.pivot(index='date', columns='ID', values='DATA VALUE')\n",
    "all_temp_df = all_temp_df / 10 * 9.0 / 5.0 + 32 # convert tenths of celsius to fahrenheit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>USC00011084</th>\n",
       "      <th>USC00012813</th>\n",
       "      <th>USC00013160</th>\n",
       "      <th>USC00013511</th>\n",
       "      <th>USC00013816</th>\n",
       "      <th>USC00017157</th>\n",
       "      <th>USC00017304</th>\n",
       "      <th>USC00017366</th>\n",
       "      <th>USC00018024</th>\n",
       "      <th>USC00018178</th>\n",
       "      <th>...</th>\n",
       "      <th>USW00093805</th>\n",
       "      <th>USW00093806</th>\n",
       "      <th>USW00093808</th>\n",
       "      <th>USW00093986</th>\n",
       "      <th>USW00094008</th>\n",
       "      <th>USW00094224</th>\n",
       "      <th>USW00094728</th>\n",
       "      <th>USW00094793</th>\n",
       "      <th>USW00094794</th>\n",
       "      <th>USW00094967</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>53.96</td>\n",
       "      <td>48.02</td>\n",
       "      <td>46.04</td>\n",
       "      <td>53.06</td>\n",
       "      <td>46.94</td>\n",
       "      <td>44.96</td>\n",
       "      <td>46.04</td>\n",
       "      <td>53.06</td>\n",
       "      <td>57.02</td>\n",
       "      <td>44.96</td>\n",
       "      <td>...</td>\n",
       "      <td>48.92</td>\n",
       "      <td>53.06</td>\n",
       "      <td>37.94</td>\n",
       "      <td>55.04</td>\n",
       "      <td>35.96</td>\n",
       "      <td>53.06</td>\n",
       "      <td>44.96</td>\n",
       "      <td>42.98</td>\n",
       "      <td>33.08</td>\n",
       "      <td>26.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-02</th>\n",
       "      <td>62.06</td>\n",
       "      <td>55.04</td>\n",
       "      <td>53.06</td>\n",
       "      <td>59.00</td>\n",
       "      <td>48.92</td>\n",
       "      <td>48.02</td>\n",
       "      <td>44.06</td>\n",
       "      <td>60.08</td>\n",
       "      <td>57.02</td>\n",
       "      <td>57.02</td>\n",
       "      <td>...</td>\n",
       "      <td>60.98</td>\n",
       "      <td>59.00</td>\n",
       "      <td>37.94</td>\n",
       "      <td>51.98</td>\n",
       "      <td>23.00</td>\n",
       "      <td>51.08</td>\n",
       "      <td>42.08</td>\n",
       "      <td>39.02</td>\n",
       "      <td>32.00</td>\n",
       "      <td>19.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-03</th>\n",
       "      <td>66.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.92</td>\n",
       "      <td>62.96</td>\n",
       "      <td>60.08</td>\n",
       "      <td>57.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.06</td>\n",
       "      <td>51.98</td>\n",
       "      <td>62.96</td>\n",
       "      <td>...</td>\n",
       "      <td>66.02</td>\n",
       "      <td>60.08</td>\n",
       "      <td>35.06</td>\n",
       "      <td>35.06</td>\n",
       "      <td>35.96</td>\n",
       "      <td>42.98</td>\n",
       "      <td>37.94</td>\n",
       "      <td>37.94</td>\n",
       "      <td>23.00</td>\n",
       "      <td>17.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-04</th>\n",
       "      <td>60.98</td>\n",
       "      <td>66.92</td>\n",
       "      <td>59.00</td>\n",
       "      <td>55.94</td>\n",
       "      <td>64.94</td>\n",
       "      <td>50.00</td>\n",
       "      <td>60.08</td>\n",
       "      <td>57.02</td>\n",
       "      <td>55.94</td>\n",
       "      <td>60.98</td>\n",
       "      <td>...</td>\n",
       "      <td>59.00</td>\n",
       "      <td>51.98</td>\n",
       "      <td>33.98</td>\n",
       "      <td>33.98</td>\n",
       "      <td>24.08</td>\n",
       "      <td>42.98</td>\n",
       "      <td>30.02</td>\n",
       "      <td>33.08</td>\n",
       "      <td>23.00</td>\n",
       "      <td>21.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-05</th>\n",
       "      <td>50.00</td>\n",
       "      <td>44.96</td>\n",
       "      <td>37.94</td>\n",
       "      <td>44.96</td>\n",
       "      <td>44.96</td>\n",
       "      <td>37.94</td>\n",
       "      <td>48.02</td>\n",
       "      <td>44.96</td>\n",
       "      <td>51.98</td>\n",
       "      <td>42.08</td>\n",
       "      <td>...</td>\n",
       "      <td>50.00</td>\n",
       "      <td>42.98</td>\n",
       "      <td>33.08</td>\n",
       "      <td>35.06</td>\n",
       "      <td>19.04</td>\n",
       "      <td>46.04</td>\n",
       "      <td>32.00</td>\n",
       "      <td>33.08</td>\n",
       "      <td>30.02</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID          USC00011084  USC00012813  USC00013160  USC00013511  USC00013816  \\\n",
       "date                                                                          \n",
       "1980-01-01        53.96        48.02        46.04        53.06        46.94   \n",
       "1980-01-02        62.06        55.04        53.06        59.00        48.92   \n",
       "1980-01-03        66.92          NaN        57.92        62.96        60.08   \n",
       "1980-01-04        60.98        66.92        59.00        55.94        64.94   \n",
       "1980-01-05        50.00        44.96        37.94        44.96        44.96   \n",
       "\n",
       "ID          USC00017157  USC00017304  USC00017366  USC00018024  USC00018178  \\\n",
       "date                                                                          \n",
       "1980-01-01        44.96        46.04        53.06        57.02        44.96   \n",
       "1980-01-02        48.02        44.06        60.08        57.02        57.02   \n",
       "1980-01-03        57.02          NaN        62.06        51.98        62.96   \n",
       "1980-01-04        50.00        60.08        57.02        55.94        60.98   \n",
       "1980-01-05        37.94        48.02        44.96        51.98        42.08   \n",
       "\n",
       "ID             ...       USW00093805  USW00093806  USW00093808  USW00093986  \\\n",
       "date           ...                                                            \n",
       "1980-01-01     ...             48.92        53.06        37.94        55.04   \n",
       "1980-01-02     ...             60.98        59.00        37.94        51.98   \n",
       "1980-01-03     ...             66.02        60.08        35.06        35.06   \n",
       "1980-01-04     ...             59.00        51.98        33.98        33.98   \n",
       "1980-01-05     ...             50.00        42.98        33.08        35.06   \n",
       "\n",
       "ID          USW00094008  USW00094224  USW00094728  USW00094793  USW00094794  \\\n",
       "date                                                                          \n",
       "1980-01-01        35.96        53.06        44.96        42.98        33.08   \n",
       "1980-01-02        23.00        51.08        42.08        39.02        32.00   \n",
       "1980-01-03        35.96        42.98        37.94        37.94        23.00   \n",
       "1980-01-04        24.08        42.98        30.02        33.08        23.00   \n",
       "1980-01-05        19.04        46.04        32.00        33.08        30.02   \n",
       "\n",
       "ID          USW00094967  \n",
       "date                     \n",
       "1980-01-01        26.96  \n",
       "1980-01-02        19.94  \n",
       "1980-01-03        17.06  \n",
       "1980-01-04        21.92  \n",
       "1980-01-05        23.00  \n",
       "\n",
       "[5 rows x 1218 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to repeat above steps after the following pickle\n",
    "with open('pickles/all_temp_df.pkl', 'wb') as file:\n",
    "    pickle.dump(all_temp_df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Estimating bias-corrected temperature time series at each station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Calculate station intercepts to minimize absolute differences between stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/fips_stations_dict.pkl', 'rb') as file:\n",
    "    fips_stations_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/all_temp_df.pkl', 'rb') as file:\n",
    "    all_temp_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>USC00011084</th>\n",
       "      <th>USC00012813</th>\n",
       "      <th>USC00013160</th>\n",
       "      <th>USC00013511</th>\n",
       "      <th>USC00013816</th>\n",
       "      <th>USC00017157</th>\n",
       "      <th>USC00017304</th>\n",
       "      <th>USC00017366</th>\n",
       "      <th>USC00018024</th>\n",
       "      <th>USC00018178</th>\n",
       "      <th>...</th>\n",
       "      <th>USW00093805</th>\n",
       "      <th>USW00093806</th>\n",
       "      <th>USW00093808</th>\n",
       "      <th>USW00093986</th>\n",
       "      <th>USW00094008</th>\n",
       "      <th>USW00094224</th>\n",
       "      <th>USW00094728</th>\n",
       "      <th>USW00094793</th>\n",
       "      <th>USW00094794</th>\n",
       "      <th>USW00094967</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>53.96</td>\n",
       "      <td>48.02</td>\n",
       "      <td>46.04</td>\n",
       "      <td>53.06</td>\n",
       "      <td>46.94</td>\n",
       "      <td>44.96</td>\n",
       "      <td>46.04</td>\n",
       "      <td>53.06</td>\n",
       "      <td>57.02</td>\n",
       "      <td>44.96</td>\n",
       "      <td>...</td>\n",
       "      <td>48.92</td>\n",
       "      <td>53.06</td>\n",
       "      <td>37.94</td>\n",
       "      <td>55.04</td>\n",
       "      <td>35.96</td>\n",
       "      <td>53.06</td>\n",
       "      <td>44.96</td>\n",
       "      <td>42.98</td>\n",
       "      <td>33.08</td>\n",
       "      <td>26.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-02</th>\n",
       "      <td>62.06</td>\n",
       "      <td>55.04</td>\n",
       "      <td>53.06</td>\n",
       "      <td>59.00</td>\n",
       "      <td>48.92</td>\n",
       "      <td>48.02</td>\n",
       "      <td>44.06</td>\n",
       "      <td>60.08</td>\n",
       "      <td>57.02</td>\n",
       "      <td>57.02</td>\n",
       "      <td>...</td>\n",
       "      <td>60.98</td>\n",
       "      <td>59.00</td>\n",
       "      <td>37.94</td>\n",
       "      <td>51.98</td>\n",
       "      <td>23.00</td>\n",
       "      <td>51.08</td>\n",
       "      <td>42.08</td>\n",
       "      <td>39.02</td>\n",
       "      <td>32.00</td>\n",
       "      <td>19.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-03</th>\n",
       "      <td>66.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.92</td>\n",
       "      <td>62.96</td>\n",
       "      <td>60.08</td>\n",
       "      <td>57.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.06</td>\n",
       "      <td>51.98</td>\n",
       "      <td>62.96</td>\n",
       "      <td>...</td>\n",
       "      <td>66.02</td>\n",
       "      <td>60.08</td>\n",
       "      <td>35.06</td>\n",
       "      <td>35.06</td>\n",
       "      <td>35.96</td>\n",
       "      <td>42.98</td>\n",
       "      <td>37.94</td>\n",
       "      <td>37.94</td>\n",
       "      <td>23.00</td>\n",
       "      <td>17.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-04</th>\n",
       "      <td>60.98</td>\n",
       "      <td>66.92</td>\n",
       "      <td>59.00</td>\n",
       "      <td>55.94</td>\n",
       "      <td>64.94</td>\n",
       "      <td>50.00</td>\n",
       "      <td>60.08</td>\n",
       "      <td>57.02</td>\n",
       "      <td>55.94</td>\n",
       "      <td>60.98</td>\n",
       "      <td>...</td>\n",
       "      <td>59.00</td>\n",
       "      <td>51.98</td>\n",
       "      <td>33.98</td>\n",
       "      <td>33.98</td>\n",
       "      <td>24.08</td>\n",
       "      <td>42.98</td>\n",
       "      <td>30.02</td>\n",
       "      <td>33.08</td>\n",
       "      <td>23.00</td>\n",
       "      <td>21.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-05</th>\n",
       "      <td>50.00</td>\n",
       "      <td>44.96</td>\n",
       "      <td>37.94</td>\n",
       "      <td>44.96</td>\n",
       "      <td>44.96</td>\n",
       "      <td>37.94</td>\n",
       "      <td>48.02</td>\n",
       "      <td>44.96</td>\n",
       "      <td>51.98</td>\n",
       "      <td>42.08</td>\n",
       "      <td>...</td>\n",
       "      <td>50.00</td>\n",
       "      <td>42.98</td>\n",
       "      <td>33.08</td>\n",
       "      <td>35.06</td>\n",
       "      <td>19.04</td>\n",
       "      <td>46.04</td>\n",
       "      <td>32.00</td>\n",
       "      <td>33.08</td>\n",
       "      <td>30.02</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID          USC00011084  USC00012813  USC00013160  USC00013511  USC00013816  \\\n",
       "date                                                                          \n",
       "1980-01-01        53.96        48.02        46.04        53.06        46.94   \n",
       "1980-01-02        62.06        55.04        53.06        59.00        48.92   \n",
       "1980-01-03        66.92          NaN        57.92        62.96        60.08   \n",
       "1980-01-04        60.98        66.92        59.00        55.94        64.94   \n",
       "1980-01-05        50.00        44.96        37.94        44.96        44.96   \n",
       "\n",
       "ID          USC00017157  USC00017304  USC00017366  USC00018024  USC00018178  \\\n",
       "date                                                                          \n",
       "1980-01-01        44.96        46.04        53.06        57.02        44.96   \n",
       "1980-01-02        48.02        44.06        60.08        57.02        57.02   \n",
       "1980-01-03        57.02          NaN        62.06        51.98        62.96   \n",
       "1980-01-04        50.00        60.08        57.02        55.94        60.98   \n",
       "1980-01-05        37.94        48.02        44.96        51.98        42.08   \n",
       "\n",
       "ID             ...       USW00093805  USW00093806  USW00093808  USW00093986  \\\n",
       "date           ...                                                            \n",
       "1980-01-01     ...             48.92        53.06        37.94        55.04   \n",
       "1980-01-02     ...             60.98        59.00        37.94        51.98   \n",
       "1980-01-03     ...             66.02        60.08        35.06        35.06   \n",
       "1980-01-04     ...             59.00        51.98        33.98        33.98   \n",
       "1980-01-05     ...             50.00        42.98        33.08        35.06   \n",
       "\n",
       "ID          USW00094008  USW00094224  USW00094728  USW00094793  USW00094794  \\\n",
       "date                                                                          \n",
       "1980-01-01        35.96        53.06        44.96        42.98        33.08   \n",
       "1980-01-02        23.00        51.08        42.08        39.02        32.00   \n",
       "1980-01-03        35.96        42.98        37.94        37.94        23.00   \n",
       "1980-01-04        24.08        42.98        30.02        33.08        23.00   \n",
       "1980-01-05        19.04        46.04        32.00        33.08        30.02   \n",
       "\n",
       "ID          USW00094967  \n",
       "date                     \n",
       "1980-01-01        26.96  \n",
       "1980-01-02        19.94  \n",
       "1980-01-03        17.06  \n",
       "1980-01-04        21.92  \n",
       "1980-01-05        23.00  \n",
       "\n",
       "[5 rows x 1218 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fips_stations_intercepts(fips, stations):\n",
    "    num_stations = len(stations)\n",
    "    # no adjustments can be made for fips with 1 or fewer stations\n",
    "    if num_stations == 0:\n",
    "        return (fips, None)\n",
    "    elif num_stations == 1:\n",
    "        return (fips, [0])\n",
    "    # df with time series for only the stations in the fips\n",
    "    fips_stations_df = all_temp_df[stations]\n",
    "    # cache both reported indeces to avoid repeated intersection computation\n",
    "    both_reported_cache = dict()\n",
    "    # array of current intercepts; updated for remaining stations every iteration\n",
    "    curr = np.full(num_stations, 0, dtype=float)\n",
    "    # array of intercepts before most recent update; used to determine convergence\n",
    "    last = np.full(num_stations, np.inf, dtype=float)\n",
    "    it = 1\n",
    "    # element-wise 'is close' to determine convergence\n",
    "    while not np.all(np.isclose(last, curr)):\n",
    "        time.sleep(0)\n",
    "#         print(f'iterations: {it}')\n",
    "#         clear_output(wait=True)\n",
    "        # reference station\n",
    "        ref_station = random.randrange(0, num_stations)\n",
    "        # remaining stations\n",
    "        rem_stations = [station for station in range(0, num_stations) if station != ref_station]\n",
    "        for rem_station in rem_stations:\n",
    "            time.sleep(0)\n",
    "            try:\n",
    "                # series for indexing the df on days where both stations reported\n",
    "                both_reported = both_reported_cache[tuple(sorted([ref_station, rem_station]))]\n",
    "            except KeyError:\n",
    "                # intersection computation\n",
    "                both_reported = fips_stations_df[stations[ref_station]].notnull() & fips_stations_df[stations[rem_station]].notnull()\n",
    "                both_reported_cache[tuple(sorted([ref_station, rem_station]))] = both_reported\n",
    "            # sum of boolean series is the simpy the number of Trues\n",
    "            n = np.sum(both_reported)\n",
    "            # only keep rows (days) where both stations reported\n",
    "            both_reported_df = fips_stations_df[both_reported]\n",
    "            # extract series for reference station\n",
    "            ref_station_reported = both_reported_df[stations[ref_station]]\n",
    "            # extract series for remaining station\n",
    "            rem_station_reported = both_reported_df[stations[rem_station]]\n",
    "            # add previous round's intercepts to respective series\n",
    "            ref_station_adjusted = ref_station_reported + curr[ref_station]\n",
    "            rem_station_adjusted = rem_station_reported + curr[rem_station]\n",
    "            diff = ref_station_adjusted - rem_station_adjusted\n",
    "            # record previous round's intercept before updating\n",
    "            last[rem_station] = curr[rem_station]\n",
    "            # update intercept\n",
    "            curr[rem_station] = curr[rem_station] + (1 / n) * np.sum(diff)\n",
    "        it += 1\n",
    "        if it > 10_000:\n",
    "            return (fips, 'max iterations exceeded')\n",
    "    # curr is a list of intercepts\n",
    "    return (fips, curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indeces correspond\n",
    "fips_codes = list(fips_stations_dict.keys())\n",
    "stations = list(fips_stations_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing time on engine(s)\n",
      "importing random on engine(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avi/anaconda3/lib/python3.7/site-packages/ipyparallel/client/client.py:459: RuntimeWarning: \n",
      "            Controller appears to be listening on localhost, but not on this machine.\n",
      "            If this is true, you should specify Client(...,sshserver='you@desk')\n",
      "            or instruct your controller to listen on an external IP.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AsyncResult: _push>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc = ipyparallel.Client()\n",
    "view = rc.load_balanced_view()\n",
    "\n",
    "with rc[:].sync_imports():\n",
    "    import time\n",
    "    import random\n",
    "\n",
    "# https://stackoverflow.com/questions/37414206/ipyparallel-view-sync-import-does-not-bind-to-additional-name\n",
    "%px import numpy as np\n",
    "\n",
    "rc[:].push(dict(\n",
    "    all_temp_df=all_temp_df\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ar = view.map_async(fips_stations_intercepts, fips_codes, stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fips_codes = len(fips_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 0:00:07\n",
      "FIPS Codes Completed: 113/3015\n",
      "Still Running\n"
     ]
    }
   ],
   "source": [
    "# ctrl + enter on this cell to see progress without blocking kernel\n",
    "print(f'Time Elapsed: {datetime.timedelta(seconds=math.ceil(ar.elapsed))}')\n",
    "print(f'FIPS Codes Completed: {ar.progress}/{num_fips_codes}')\n",
    "print(f'Completed {round(ar.serial_time/ar.wall_time, 2)}x faster than serial computation' if ar.ready() else 'Still Running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3015/3015 tasks finished after  825 s\n",
      "done\n",
      "Completed 11.47x faster than serial computation\n"
     ]
    }
   ],
   "source": [
    "# will block the kernel; interrupt the kernel to unblock\n",
    "ar.wait_interactive()\n",
    "print(f'Completed {round(ar.serial_time/ar.wall_time, 2)}x faster than serial computation' if ar.ready() else 'Still Running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "fips_stations_intercepts_dict = dict()\n",
    "# the intercepts for these fips codes are not converging\n",
    "fips_codes_to_check = list()\n",
    "for fips, intercepts in ar:\n",
    "    # TODO: what to do with fips with no stations?\n",
    "    if intercepts is None:\n",
    "        continue\n",
    "    elif intercepts == 'max iterations exceeded':\n",
    "        fips_codes_to_check.append(fips)\n",
    "        continue\n",
    "    stations = fips_stations_dict[fips]\n",
    "    for station, intercept in zip(stations, intercepts):\n",
    "        try:\n",
    "            fips_stations_intercepts_dict[fips][station] = intercept\n",
    "        except KeyError:\n",
    "            fips_stations_intercepts_dict[fips] = {station: intercept}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: analyze manually\n",
    "len(fips_codes_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/fips_stations_intercepts_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(fips_stations_intercepts_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Adjust all intercepts to reflect typical county weather conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/fips_stations_inverse_distances_dict.pkl', 'rb') as file:\n",
    "    fips_stations_inverse_distances_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/fips_stations_intercepts_dict.pkl', 'rb') as file:\n",
    "    fips_stations_intercepts_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fips, stations_intercepts_dict in fips_stations_intercepts_dict.items():\n",
    "    stations_inverse_distances_dict = fips_stations_inverse_distances_dict[fips]\n",
    "    weights = np.array(list(stations_inverse_distances_dict.values()))\n",
    "    intercepts = np.array(list(stations_intercepts_dict.values()))\n",
    "    weighted_average = np.sum(weights * intercepts) / np.sum(weights)\n",
    "    for station in stations_intercepts_dict.keys():\n",
    "        fips_stations_intercepts_dict[fips][station] -= weighted_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculating weighted average weather for each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIPS Codes: 3015/3015\n"
     ]
    }
   ],
   "source": [
    "fips_temp_dict = dict()\n",
    "num_fips_codes = len(fips_stations_dict)\n",
    "for i, (fips, stations) in enumerate(fips_stations_dict.items()):\n",
    "    print(f'FIPS Codes: {i+1}/{num_fips_codes}')\n",
    "    clear_output(wait=True)\n",
    "    try:\n",
    "        stations_intercepts_dict = fips_stations_intercepts_dict[fips]\n",
    "    # occurs only when fips has no stations\n",
    "    except KeyError:\n",
    "        continue\n",
    "    stations_inverse_distances_dict = fips_stations_inverse_distances_dict[fips]\n",
    "    fips_stations_df = all_temp_df[stations]\n",
    "    intercepts = np.array(list(stations_intercepts_dict.values()))\n",
    "    if isinstance(intercepts[0], str):\n",
    "        continue\n",
    "    weights = np.array(list(stations_inverse_distances_dict.values()))\n",
    "    # adjust each station's temp series by the calculated intercept\n",
    "    fips_stations_df += intercepts\n",
    "    # apply calculated weights to each station's temp series\n",
    "    fips_stations_df *= weights\n",
    "    # take weighted average of each station\n",
    "    fips_temp_dict[fips] = fips_stations_df.sum(axis=1) / np.sum(weights)\n",
    "fips_temp_df = pd.DataFrame(fips_temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>27077</th>\n",
       "      <th>53073</th>\n",
       "      <th>53047</th>\n",
       "      <th>53019</th>\n",
       "      <th>16021</th>\n",
       "      <th>30101</th>\n",
       "      <th>30105</th>\n",
       "      <th>30091</th>\n",
       "      <th>38023</th>\n",
       "      <th>38013</th>\n",
       "      <th>...</th>\n",
       "      <th>12099</th>\n",
       "      <th>12071</th>\n",
       "      <th>48427</th>\n",
       "      <th>12051</th>\n",
       "      <th>48489</th>\n",
       "      <th>48215</th>\n",
       "      <th>12021</th>\n",
       "      <th>12011</th>\n",
       "      <th>12086</th>\n",
       "      <th>12087</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>18.712920</td>\n",
       "      <td>36.685883</td>\n",
       "      <td>32.000951</td>\n",
       "      <td>25.918505</td>\n",
       "      <td>35.831735</td>\n",
       "      <td>45.079819</td>\n",
       "      <td>36.754023</td>\n",
       "      <td>30.515072</td>\n",
       "      <td>25.709490</td>\n",
       "      <td>24.98</td>\n",
       "      <td>...</td>\n",
       "      <td>67.618750</td>\n",
       "      <td>64.837862</td>\n",
       "      <td>67.282964</td>\n",
       "      <td>66.043967</td>\n",
       "      <td>64.04</td>\n",
       "      <td>66.407741</td>\n",
       "      <td>72.301503</td>\n",
       "      <td>59.468211</td>\n",
       "      <td>23.376757</td>\n",
       "      <td>56.614433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-02</th>\n",
       "      <td>11.071802</td>\n",
       "      <td>38.492549</td>\n",
       "      <td>31.004428</td>\n",
       "      <td>24.825643</td>\n",
       "      <td>37.158181</td>\n",
       "      <td>43.951076</td>\n",
       "      <td>24.790933</td>\n",
       "      <td>19.102348</td>\n",
       "      <td>16.391507</td>\n",
       "      <td>15.98</td>\n",
       "      <td>...</td>\n",
       "      <td>64.426049</td>\n",
       "      <td>63.727822</td>\n",
       "      <td>71.060000</td>\n",
       "      <td>64.250718</td>\n",
       "      <td>71.06</td>\n",
       "      <td>71.060000</td>\n",
       "      <td>68.241944</td>\n",
       "      <td>55.292479</td>\n",
       "      <td>21.693056</td>\n",
       "      <td>51.098822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-03</th>\n",
       "      <td>7.251181</td>\n",
       "      <td>35.231312</td>\n",
       "      <td>27.912066</td>\n",
       "      <td>24.301328</td>\n",
       "      <td>37.655729</td>\n",
       "      <td>37.492174</td>\n",
       "      <td>35.184564</td>\n",
       "      <td>28.116247</td>\n",
       "      <td>21.955243</td>\n",
       "      <td>21.02</td>\n",
       "      <td>...</td>\n",
       "      <td>63.711470</td>\n",
       "      <td>71.047895</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>67.186110</td>\n",
       "      <td>77.00</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>67.490662</td>\n",
       "      <td>60.555283</td>\n",
       "      <td>24.399004</td>\n",
       "      <td>55.907304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-04</th>\n",
       "      <td>16.446460</td>\n",
       "      <td>32.616167</td>\n",
       "      <td>24.994008</td>\n",
       "      <td>22.791679</td>\n",
       "      <td>32.033837</td>\n",
       "      <td>34.412249</td>\n",
       "      <td>24.238771</td>\n",
       "      <td>25.893898</td>\n",
       "      <td>22.443736</td>\n",
       "      <td>21.92</td>\n",
       "      <td>...</td>\n",
       "      <td>73.427716</td>\n",
       "      <td>69.110040</td>\n",
       "      <td>61.175555</td>\n",
       "      <td>69.793249</td>\n",
       "      <td>62.06</td>\n",
       "      <td>61.414252</td>\n",
       "      <td>72.059558</td>\n",
       "      <td>65.103943</td>\n",
       "      <td>25.721912</td>\n",
       "      <td>59.018674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-05</th>\n",
       "      <td>22.254658</td>\n",
       "      <td>30.571894</td>\n",
       "      <td>26.852318</td>\n",
       "      <td>23.645513</td>\n",
       "      <td>31.599524</td>\n",
       "      <td>28.359593</td>\n",
       "      <td>15.929085</td>\n",
       "      <td>16.641174</td>\n",
       "      <td>15.285754</td>\n",
       "      <td>15.08</td>\n",
       "      <td>...</td>\n",
       "      <td>68.551042</td>\n",
       "      <td>65.280600</td>\n",
       "      <td>65.135555</td>\n",
       "      <td>66.904356</td>\n",
       "      <td>66.02</td>\n",
       "      <td>65.374252</td>\n",
       "      <td>68.732165</td>\n",
       "      <td>56.903173</td>\n",
       "      <td>22.053849</td>\n",
       "      <td>53.503063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2970 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                27077      53073      53047      53019      16021      30101  \\\n",
       "date                                                                           \n",
       "1980-01-01  18.712920  36.685883  32.000951  25.918505  35.831735  45.079819   \n",
       "1980-01-02  11.071802  38.492549  31.004428  24.825643  37.158181  43.951076   \n",
       "1980-01-03   7.251181  35.231312  27.912066  24.301328  37.655729  37.492174   \n",
       "1980-01-04  16.446460  32.616167  24.994008  22.791679  32.033837  34.412249   \n",
       "1980-01-05  22.254658  30.571894  26.852318  23.645513  31.599524  28.359593   \n",
       "\n",
       "                30105      30091      38023  38013    ...          12099  \\\n",
       "date                                                  ...                  \n",
       "1980-01-01  36.754023  30.515072  25.709490  24.98    ...      67.618750   \n",
       "1980-01-02  24.790933  19.102348  16.391507  15.98    ...      64.426049   \n",
       "1980-01-03  35.184564  28.116247  21.955243  21.02    ...      63.711470   \n",
       "1980-01-04  24.238771  25.893898  22.443736  21.92    ...      73.427716   \n",
       "1980-01-05  15.929085  16.641174  15.285754  15.08    ...      68.551042   \n",
       "\n",
       "                12071      48427      12051  48489      48215      12021  \\\n",
       "date                                                                       \n",
       "1980-01-01  64.837862  67.282964  66.043967  64.04  66.407741  72.301503   \n",
       "1980-01-02  63.727822  71.060000  64.250718  71.06  71.060000  68.241944   \n",
       "1980-01-03  71.047895  77.000000  67.186110  77.00  77.000000  67.490662   \n",
       "1980-01-04  69.110040  61.175555  69.793249  62.06  61.414252  72.059558   \n",
       "1980-01-05  65.280600  65.135555  66.904356  66.02  65.374252  68.732165   \n",
       "\n",
       "                12011      12086      12087  \n",
       "date                                         \n",
       "1980-01-01  59.468211  23.376757  56.614433  \n",
       "1980-01-02  55.292479  21.693056  51.098822  \n",
       "1980-01-03  60.555283  24.399004  55.907304  \n",
       "1980-01-04  65.103943  25.721912  59.018674  \n",
       "1980-01-05  56.903173  22.053849  53.503063  \n",
       "\n",
       "[5 rows x 2970 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips_temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/fips_temp_df.pkl', 'wb') as file:\n",
    "    pickle.dump(fips_temp_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: repeat for precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
