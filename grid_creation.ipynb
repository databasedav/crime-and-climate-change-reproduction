{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Creation\n",
    "\n",
    "Requires local Nominatim server covering the continental United States at the minimum. Because hundreds of thousands of reverse geolocation queries must be made and then organized, the code below does many operations asynchronously. See https://ipython-books.github.io/59-distributing-python-code-across-multiple-cores-with-ipython/ and https://ipython-books.github.io/510-interacting-with-asynchronous-parallel-tasks-in-ipython/ for setup and more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import ipyparallel\n",
    "import ipywidgets\n",
    "import os.path\n",
    "import pickle\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "from geopy import Point, distance\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderServiceError, GeocoderTimedOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the progess bar is optional and will lock the kernel for the\n",
    "# duration of the task.\n",
    "def progress_bar(ar):\n",
    "    w = ipywidgets.IntProgress()\n",
    "    w.max = len(ar.msg_ids)\n",
    "    display(w)\n",
    "    while not ar.ready():\n",
    "        w.value = ar.progress\n",
    "        time.sleep(.1)\n",
    "    w.value = w.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate to County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_to_county(coord):\n",
    "    \"\"\"\n",
    "    Returns county from entered coordinate.\n",
    "    coord: tuple consisting of (latitude, longitude)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        time.sleep(.01)\n",
    "        raw = geolocator.reverse(coord).raw\n",
    "        if raw['address']['country_code'] != 'us':\n",
    "            return (coord, None)\n",
    "        return (coord, raw['address']['county'])\n",
    "    # investigate errors manually\n",
    "    except (GeocoderServiceError, GeocoderTimedOut, KeyError) as e:\n",
    "        return (coord, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_generator(min_lat, max_lat, min_lon, max_lon, dist):\n",
    "    \"\"\"\n",
    "    Returns list of (latitude, longitude) tuples bounded by the given\n",
    "    minimum and maximum latitudes and longitudes.\n",
    "    \"\"\"\n",
    "    start = Point(max_lat, min_lon)\n",
    "    point = start\n",
    "    \n",
    "    def point_to_tuple(point):\n",
    "        return (point.latitude, point.longitude)\n",
    "    \n",
    "    coord = point_to_tuple(point)\n",
    "    ver_dist = distance.distance(miles=dist)\n",
    "    hor_dist = distance.distance(miles=dist)\n",
    "    coords = list() # list of coords forming the grid\n",
    "    \n",
    "    while True:\n",
    "        # eastmost bound reached\n",
    "        if coord[1] > max_lon:\n",
    "            # go back to starting point and move south\n",
    "            point = ver_dist.destination(point=start, bearing=180)\n",
    "            # increment vertical distance\n",
    "            ver_dist += distance.distance(miles=5)\n",
    "        # southmost bound reached\n",
    "        elif coord[0] < min_lat:\n",
    "            break\n",
    "        yield coord\n",
    "        # move east\n",
    "        point = hor_dist.destination(point=point, bearing=90)\n",
    "        coord = point_to_tuple(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(domain='localhost:8080', scheme='http')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_lat = None\n",
    "max_lat= None\n",
    "min_lon = None\n",
    "max_lon = None\n",
    "dist = 5\n",
    "coords = list(coordinate_generator(min_lat, max_lat, min_lon, max_lon, dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = ipyparallel.Client()\n",
    "view = rc.load_balanced_view()\n",
    "\n",
    "with rc[:].sync_imports():\n",
    "    import time\n",
    "\n",
    "rc[:].push(dict(\n",
    "    geolocator=geolocator,\n",
    "    GeocoderServiceError=GeocoderServiceError,\n",
    "    GeocoderTimedOut=GeocoderTimedOut\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = view.map_async(coord_to_county, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can check progress without locking kernel with this cell\n",
    "ar.elapsed # time\n",
    "ar.progress # number of coordinates that have returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the progress bar will lock the kernel\n",
    "# progress_bar(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict from coordinate to county in US, None if not in US, or an error object\n",
    "try:\n",
    "    with open('pickles/coord_county_dict.pkl', 'rb') as file:\n",
    "        coord_county_dict = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    coord_county_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coord, maybe_county in ar:\n",
    "    if coord not in coord_county_dict:\n",
    "        coord_county_dict[coord] = maybe_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/coord_county_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(coord_county_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## County Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loop is fast and need not be pickled\n",
    "# dict from county name to list of coordinates within said county\n",
    "county_coords_dict = dict()\n",
    "skipped = list()\n",
    "for coord, county in coord_county_dict:\n",
    "    if not isinstance(county, str):\n",
    "        skipped.append((coord, county))\n",
    "        continue\n",
    "    try:\n",
    "        county_coords_dict[county].append(coord)\n",
    "    except KeyError:\n",
    "        county_coords_dict[county] = [coord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze skipped coords, potentially rerunning them manually\n",
    "skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## County Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stations_df = pd.read_fwf('weather_data/stations.txt',\n",
    "       colspecs=[(0,11), (12, 20), (21, 30), (31, 37), (38, 40), (41, 71), (72, 75), (76, 79), (80, 85)],\n",
    "       header=None,\n",
    "       names=['ID', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'STATE', 'NAME', 'GSN FLAG', 'HCN/CRN FLAG', 'WMO ID'])\n",
    "except FileNotFoundError:\n",
    "    url = 'https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt'\n",
    "    urllib.request.urlretrieve(url, 'weather_data/stations.txt')\n",
    "    stations_df = pd.read_fwf('stations.txt',\n",
    "       colspecs=[(0,11), (12, 20), (21, 30), (31, 37), (38, 40), (41, 71), (72, 75), (76, 79), (80, 85)],\n",
    "       header=None,\n",
    "       names=['ID', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'STATE', 'NAME', 'GSN FLAG', 'HCN/CRN FLAG', 'WMO ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only includes HCN stations in the continental United States\n",
    "stations_df = stations_df[stations_df['ID'].str.startswith('US') & (stations_df['HCN/CRN FLAG'] == 'HCN')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stations_to_county(county):\n",
    "    coords = county_coords[county]\n",
    "    county_stations = list()\n",
    "    time.sleep(.01)\n",
    "    for i, station in stations_df.iterrows():\n",
    "        station_coord = (station['LATITUDE'], station['LONGITUDE'])\n",
    "        time.sleep(.01)\n",
    "        for coord in coords:\n",
    "            dist = distance(station_coord, coord).miles\n",
    "            if dist <= 50:\n",
    "                county_stations.append(station['ID'])\n",
    "                break\n",
    "    return (county, county_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counties = list(county_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = ipyparallel.Client()\n",
    "view = rc.load_balanced_view()\n",
    "\n",
    "with rc[:].sync_imports():\n",
    "    import time\n",
    "\n",
    "rc[:].push(dict(\n",
    "    distance=distance.distance,\n",
    "    county_coords=county_coords,\n",
    "    stations_df=stations_df\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = view.map_async(add_stations_to_county, counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can check progress without locking kernel with this cell\n",
    "ar.elapsed # time\n",
    "ar.progress # number of coordinates that have returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the progress bar will lock the kernel\n",
    "# progress_bar(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict from coordinate to county in US, None if not in US, or an error object\n",
    "try:\n",
    "    with open('pickles/county_stations_dict.pkl', 'rb') as file:\n",
    "        county_stations_dict = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    county_stations_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for county, stations in ar:\n",
    "    if county not in county_stations_dict:\n",
    "        county_stations_dict[county] = stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/county_stations_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(county_stations_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index to ID for fast lookup\n",
    "stations_df.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loop is fairly fast so I haven't pickled it\n",
    "# dict from county to dict of station to inverse average distance\n",
    "area_weighted_inverse_distances = dict()\n",
    "for i, (county, stations) in enumerate(county_stations.items()):\n",
    "    for j, station in enumerate(stations):\n",
    "        print(f'county: {i+1}/{len(county_stations)}\\nstations: {j+1}/{len(stations)}')\n",
    "        clear_output(wait=True)\n",
    "        distances = list()\n",
    "        station_coord = (stations_df.loc[station]['LATITUDE'], stations_df.loc[station]['LONGITUDE'])\n",
    "        for coord in county_coords[county]:\n",
    "            distances.append(distance.distance(station_coord, coord).miles)\n",
    "        distances = np.array(distances, dtype=float)\n",
    "        inverse_distances = np.reciprocal(distances)\n",
    "        try:\n",
    "            area_weighted_inverse_distances[county][station] = np.mean(inverse_distances)\n",
    "        except KeyError:\n",
    "            area_weighted_inverse_distances[county] = {station: np.mean(inverse_distances)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
